spring:
  kafka:
    producer:
      bootstrap-servers: localhost:9092
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      batch-size: 16384
      properties:
        linger.ms: 100
        compression.type: lz4
        enable.idempotence: true
        max.request.size: 20971520
      acks: "all"
    consumer:
      bootstrap-servers: localhost:9092
      enable-auto-commit: false
      group-id: consumer-dev
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      max-poll-records: 500
      heartbeat-interval: 3000
      properties:
        partition.assignment.strategy: org.apache.kafka.clients.consumer.CooperativeStickyAssignor  # 使用协作式分配器
        max.poll.interval.ms: 300000  # 增加轮询间隔，允许更长的处理时间
      fetch-min-size: 1
      fetch-max-wait: 500

  redis:
    host: localhost
    database: 8
    password:
    timeout: 300000  # 添加连接超时时间（毫秒）
    lettuce: # 使用Lettuce客户端
      pool:
        max-active: 8
        max-idle: 8
        min-idle: 0
        max-wait: -1ms

logging:
  level:
    org.springframework.kafka: INFO

# 添加线程池配置
thread-pool:
  core-pool-size: 10
  max-pool-size: 20
  queue-capacity: 100
  keep-alive-seconds: 300